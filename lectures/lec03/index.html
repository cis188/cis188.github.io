<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Reproducibility: docker compose | CIS 188: DevOps</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Reproducibility: docker compose"><meta property="og:description" content="Coming soon!
Demos Docker&rsquo;s implementation of images and containers is wonderful because it allows us to easily package up and send application code to another machine with strong guarantees that the code will work on the target machine. However, we are still missing a crucial component.
Taking our Docker images and spinning up the containers is, as far as we have seen, a fairly manual process. We have used the Docker CLI to download, build, and run containers."><meta property="og:type" content="article"><meta property="og:url" content="https://cis188.org/lectures/lec03/"><meta property="article:published_time" content="2020-12-01T00:00:00+00:00"><meta property="article:modified_time" content="2021-02-15T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Reproducibility: docker compose"><meta name=twitter:description content="Coming soon!
Demos Docker&rsquo;s implementation of images and containers is wonderful because it allows us to easily package up and send application code to another machine with strong guarantees that the code will work on the target machine. However, we are still missing a crucial component.
Taking our Docker images and spinning up the containers is, as far as we have seen, a fairly manual process. We have used the Docker CLI to download, build, and run containers."><link rel=stylesheet href=https://cis188.org/css/style-white.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://cis188.org/img/favicon.ico></head><body><div class="max-width mx-auto px3 ltr"><div class="content index py4"><header id=header><a href=https://cis188.org/><div id=logo style=background-image:url(https://cis188.org/img/logo.png)></div><div id=title><h1>CIS 188: DevOps</h1></div></a><div id=nav><ul><li class=icon><a href=#><i class="fas fa-bars fa-2x"></i></a></li><li><a href=/>Home</a></li><li><a href=/lectures/>Schedule</a></li><li><a href=/syllabus/>Syllabus</a></li><li><a href=/staff/>Staff</a></li><li><a href=https://www.gradescope.com/courses/229689>Gradescope</a></li><li><a href=https://piazza.com/upenn/spring2021/cis188/home>Piazza</a></li></ul></div></header><style>.main-content{font-family:BlinkMacSystemFont,-apple-system,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,Helvetica,Arial,sans-serif}#header #logo{filter:none;-webkit-filter:none;background-size:contain;border-radius:0}</style><div class=main-content><article class=post itemscope itemtype=http://schema.org/BlogPosting><style>.content{max-width:80ch}.content>h1{font-weight:700;font-size:2.5rem;margin-top:0;margin-bottom:1rem;color:#000}.content>h2{font-size:2rem;margin-top:0;margin-bottom:.2rem}.content>h2:before{content:""!important}.content>h3{font-size:1.25rem}.content>p,.content>li{font-size:16px!important;hyphens:none!important;-moz-hyphens:none!important;-ms-hyphens:none!important;-webkit-hyphens:none!important}</style><div class=content itemprop=articleBody><p>Coming soon!</p><h2 id=demos>Demos</h2><p>Docker&rsquo;s implementation of images and containers is wonderful because it allows us to easily package up and send application code to another machine with strong guarantees that the code will work on the target machine. However, we are still missing a crucial component.</p><p>Taking our Docker images and spinning up the containers is, as far as we have seen, a fairly manual process. We have used the Docker CLI to download, build, and run containers. What happens when we have multiple containers we want to run in collaboration (maybe a frontend, backend framework)? What if there are specific parameters we want to set for certain containers (mounting a volume, joining a network, etc.)? This is where Docker compose comes into play.</p><p>Docker compose allows us to automate the process of installing, building, configuring, and running our Docker containers. You could argue that this is something we could do with a shell script of the commands we would run in the CLI, but you&rsquo;ll quickly see that this is brittle and hard for developers to understand or update. Instead, Docker compose allows us to write YAML files which are readable and clearly outline the configuration of each container.</p><p>So, let&rsquo;s jump right into the example. In lecture, we noted that because Docker uses a copy-on-write filesystem, when changes are made to the filesystem during Docker runtime, those changes are discarded after the container is closed. Let&rsquo;s see if we can write a Docker compose file to create a container that will mount a volume so we can save logs made during the runtime of our program.</p><p>If you&rsquo;ve already cloned the website repository, you can find the code for this demo in <code>demos/docker_compose_demo</code> (if you need instructions for cloning the repository, take a look at the Docker demo from last week). Let&rsquo;s quickly look over the biggest new addition to the demo, <code>docker_compose.yml</code>. This is a relatively short file with the contents:</p><pre><code>version: '3'
services:
  docker_compose_demo_container:
    build: .
    ports:
      - &quot;8080:8080&quot;
    volumes:
      - type: bind
        source: ./log
        target: /log
</code></pre><p>The <code>version</code> number specifies what version of Docker compose we are using. The <code>services</code> is a list of containers that we want to create, and we can also specify how to build the images that run. We build the current working directory to start the container, and expose port <code>8080</code> (normally something we added as a command line argument). The reason <code>build .</code> works in this context is because Docker compose will look for the Dockerfile in the current working directory, and use that Dockerfile to build the image. Lastly, the new thing we do here is bind a volume. We tell Docker that we want it to share the <code>./log</code> directory (which we see in our current working directory) with <code>/log</code> on the container. So, in our <code>index.js</code> when we write to <code>/log</code>, Docker will also write the same data to <code>./log</code>.</p><p>Let&rsquo;s give it a try:</p><pre><code># Build image and run container according to specifications in docker-compose.yml
$ docker-compose up
</code></pre><p>After building our image specified in the Dockerfile and creating the container to run it, if we navigate to <code>localhost:8080</code> we should see the text <code>Logged request to /log.txt!</code>. Let&rsquo;s check out the <code>index.js</code> file, we can see what&rsquo;s really happening here:</p><pre><code>const server = http.createServer((req, res) =&gt; {
  fs.appendFile('/log/log.txt', JSON.stringify(req.headers) + &quot;\n\n&quot;, (error, data) =&gt; {
    if (error) {
      return console.log(error);
    }
    console.log(data);
  });
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Logged request to /log.txt!');
});
</code></pre><p>Essentially, Node gets the request, logs the headers of the request to <code>/log/log.txt</code>, and then displays <code>Logged request to /log.txt!</code>. So, if Node is writing to <code>/log/log.txt</code> and we bound that directory to <code>./log</code> that means that the logs are also stored in <code>./log/log.txt</code>! Open up <code>./log/log.txt</code> and check out the contents, you will see that the logs the headers of the requests that you make to <code>localhost:8080</code>. More than that, it updates live. So, if you close the file, make a request, and reopen the file, you will see that new log in the file.</p><p>Note that Docker has a much easier time with this than a virtual machine would. When you share a volume between the host and a virtual machine, you have two separate kernels which both have to recognize it as a shared volume. Docker has an easier time because it&rsquo;s the same kernel on both processes, it just needs to expose the correct volume to the kernel.</p><p>Feel free to play around with logging and other ways to interact with a shared volume. You can also change the configurations to share different volumes. You can also experiment with running two separate containers with a single Docker compose file, this is really when Docker compose starts to be a huge improvement over managing each container individually. This is something you&rsquo;ll get a lot of good experience with during homework two.</p></div></article></div><footer id=footer><div class=footer-left>Copyright &copy; 2021 CIS 188: DevOps</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/lectures/>Schedule</a></li><li><a href=/syllabus/>Syllabus</a></li><li><a href=/staff/>Staff</a></li><li><a href=https://www.gradescope.com/courses/229689>Gradescope</a></li><li><a href=https://piazza.com/upenn/spring2021/cis188/home>Piazza</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script><script src=/js/main.js></script></html>